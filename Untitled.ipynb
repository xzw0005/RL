{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of actions = 2\n",
      "state dimention = 4\n"
     ]
    }
   ],
   "source": [
    "print(\"number of actions = {}\".format(env.action_space.n))\n",
    "print(\"state dimention = {}\".format(env.observation_space.shape[0]))\n",
    "nActions = env.action_space.n\n",
    "stateSize = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(env, parameters):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    state.reshape([1, stateSize])\n",
    "    total_rewards = 0\n",
    "    time_step = 0\n",
    "    while not done and time_step < 200:\n",
    "#         action = np.random.randint(0, nActions)\n",
    "        action = 1\n",
    "        if np.matmul(state, parameters) < 0:\n",
    "            action = 0\n",
    "#         env.render()\n",
    "        time_step += 1\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        total_rewards += reward\n",
    "        state = np.reshape(next_state, [1, stateSize])\n",
    "    return total_rewards, time_step\n",
    "#     print \"episode {}\".format(ep)\n",
    "#     print \"\\t total reward = {}\".format(total_rewards)\n",
    "#     print \"\\t time step = {}\".format(time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 88.0\n",
      "1 25.0\n",
      "2 10.0\n",
      "3 43.0\n",
      "4 9.0\n",
      "5 11.0\n",
      "6 71.0\n",
      "7 10.0\n",
      "8 25.0\n",
      "9 78.0\n",
      "10 8.0\n",
      "11 200.0\n"
     ]
    }
   ],
   "source": [
    "best_params = None\n",
    "best_reward = 0\n",
    "for episode in range(1000):\n",
    "    params = np.random.rand(stateSize, 1) * 2 - 1\n",
    "    G, T = run_episode(env, params)\n",
    "    print(episode, G)\n",
    "    if G > best_reward:\n",
    "        best_reward = G\n",
    "        best_params = params\n",
    "        if G >= 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill Climbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 53.0\n",
      "1 68.0\n",
      "2 92.0\n",
      "3 72.0\n",
      "4 47.0\n",
      "5 54.0\n",
      "6 65.0\n",
      "7 50.0\n",
      "8 38.0\n",
      "9 49.0\n",
      "10 38.0\n",
      "11 42.0\n",
      "12 58.0\n",
      "13 75.0\n",
      "14 38.0\n",
      "15 48.0\n",
      "16 44.0\n",
      "17 48.0\n",
      "18 34.0\n",
      "19 50.0\n",
      "20 80.0\n",
      "21 36.0\n",
      "22 106.0\n",
      "23 56.0\n",
      "24 56.0\n",
      "25 65.0\n",
      "26 57.0\n",
      "27 46.0\n",
      "28 38.0\n",
      "29 162.0\n",
      "30 44.0\n",
      "31 46.0\n",
      "32 40.0\n",
      "33 169.0\n",
      "34 48.0\n",
      "35 88.0\n",
      "36 45.0\n",
      "37 102.0\n",
      "38 48.0\n",
      "39 77.0\n",
      "40 35.0\n",
      "41 75.0\n",
      "42 77.0\n",
      "43 43.0\n",
      "44 58.0\n",
      "45 56.0\n",
      "46 65.0\n",
      "47 122.0\n",
      "48 108.0\n",
      "49 45.0\n",
      "50 58.0\n",
      "51 62.0\n",
      "52 66.0\n",
      "53 57.0\n",
      "54 51.0\n",
      "55 94.0\n",
      "56 77.0\n",
      "57 72.0\n",
      "58 90.0\n",
      "59 50.0\n",
      "60 89.0\n",
      "61 53.0\n",
      "62 48.0\n",
      "63 93.0\n",
      "64 38.0\n",
      "65 42.0\n",
      "66 48.0\n",
      "67 49.0\n",
      "68 73.0\n",
      "69 131.0\n",
      "70 69.0\n",
      "71 56.0\n",
      "72 145.0\n",
      "73 39.0\n",
      "74 89.0\n",
      "75 37.0\n",
      "76 40.0\n",
      "77 55.0\n",
      "78 50.0\n",
      "79 106.0\n",
      "80 70.0\n",
      "81 118.0\n",
      "82 70.0\n",
      "83 46.0\n",
      "84 49.0\n",
      "85 60.0\n",
      "86 175.0\n",
      "87 68.0\n",
      "88 70.0\n",
      "89 39.0\n",
      "90 42.0\n",
      "91 39.0\n",
      "92 40.0\n",
      "93 70.0\n",
      "94 108.0\n",
      "95 93.0\n",
      "96 40.0\n",
      "97 67.0\n",
      "98 63.0\n",
      "99 74.0\n",
      "100 62.0\n",
      "101 35.0\n",
      "102 37.0\n",
      "103 67.0\n",
      "104 49.0\n",
      "105 70.0\n",
      "106 127.0\n",
      "107 100.0\n",
      "108 117.0\n",
      "109 66.0\n",
      "110 44.0\n",
      "111 65.0\n",
      "112 42.0\n",
      "113 51.0\n",
      "114 73.0\n",
      "115 70.0\n",
      "116 85.0\n",
      "117 55.0\n",
      "118 48.0\n",
      "119 42.0\n",
      "120 59.0\n",
      "121 68.0\n",
      "122 89.0\n",
      "123 65.0\n",
      "124 39.0\n",
      "125 57.0\n",
      "126 80.0\n",
      "127 40.0\n",
      "128 84.0\n",
      "129 48.0\n",
      "130 68.0\n",
      "131 56.0\n",
      "132 52.0\n",
      "133 59.0\n",
      "134 74.0\n",
      "135 94.0\n",
      "136 63.0\n",
      "137 92.0\n",
      "138 53.0\n",
      "139 116.0\n",
      "140 56.0\n",
      "141 68.0\n",
      "142 39.0\n",
      "143 52.0\n",
      "144 42.0\n",
      "145 38.0\n",
      "146 39.0\n",
      "147 75.0\n",
      "148 127.0\n",
      "149 148.0\n",
      "150 86.0\n",
      "151 56.0\n",
      "152 148.0\n",
      "153 63.0\n",
      "154 42.0\n",
      "155 68.0\n",
      "156 38.0\n",
      "157 44.0\n",
      "158 82.0\n",
      "159 80.0\n",
      "160 42.0\n",
      "161 149.0\n",
      "162 72.0\n",
      "163 70.0\n",
      "164 129.0\n",
      "165 40.0\n",
      "166 66.0\n",
      "167 50.0\n",
      "168 58.0\n",
      "169 54.0\n",
      "170 63.0\n",
      "171 101.0\n",
      "172 44.0\n",
      "173 47.0\n",
      "174 56.0\n",
      "175 85.0\n",
      "176 128.0\n",
      "177 38.0\n",
      "178 41.0\n",
      "179 44.0\n",
      "180 53.0\n",
      "181 62.0\n",
      "182 49.0\n",
      "183 50.0\n",
      "184 66.0\n",
      "185 64.0\n",
      "186 73.0\n",
      "187 72.0\n",
      "188 67.0\n",
      "189 41.0\n",
      "190 75.0\n",
      "191 59.0\n",
      "192 44.0\n",
      "193 135.0\n",
      "194 80.0\n",
      "195 84.0\n",
      "196 53.0\n",
      "197 68.0\n",
      "198 62.0\n",
      "199 53.0\n",
      "200 65.0\n",
      "201 46.0\n",
      "202 82.0\n",
      "203 69.0\n",
      "204 111.0\n",
      "205 48.0\n",
      "206 45.0\n",
      "207 58.0\n",
      "208 95.0\n",
      "209 75.0\n",
      "210 70.0\n",
      "211 61.0\n",
      "212 61.0\n",
      "213 47.0\n",
      "214 84.0\n",
      "215 44.0\n",
      "216 58.0\n",
      "217 132.0\n",
      "218 59.0\n",
      "219 130.0\n",
      "220 69.0\n",
      "221 84.0\n",
      "222 84.0\n",
      "223 177.0\n",
      "224 44.0\n",
      "225 53.0\n",
      "226 127.0\n",
      "227 72.0\n",
      "228 121.0\n",
      "229 66.0\n",
      "230 103.0\n",
      "231 35.0\n",
      "232 53.0\n",
      "233 94.0\n",
      "234 68.0\n",
      "235 63.0\n",
      "236 60.0\n",
      "237 86.0\n",
      "238 111.0\n",
      "239 76.0\n",
      "240 57.0\n",
      "241 49.0\n",
      "242 59.0\n",
      "243 39.0\n",
      "244 63.0\n",
      "245 50.0\n",
      "246 50.0\n",
      "247 105.0\n",
      "248 52.0\n",
      "249 61.0\n",
      "250 95.0\n",
      "251 109.0\n",
      "252 56.0\n",
      "253 67.0\n",
      "254 90.0\n",
      "255 49.0\n",
      "256 53.0\n",
      "257 39.0\n",
      "258 96.0\n",
      "259 99.0\n",
      "260 59.0\n",
      "261 81.0\n",
      "262 69.0\n",
      "263 71.0\n",
      "264 57.0\n",
      "265 97.0\n",
      "266 147.0\n",
      "267 131.0\n",
      "268 84.0\n",
      "269 84.0\n",
      "270 109.0\n",
      "271 73.0\n",
      "272 57.0\n",
      "273 57.0\n",
      "274 78.0\n",
      "275 183.0\n",
      "276 69.0\n",
      "277 63.0\n",
      "278 83.0\n",
      "279 83.0\n",
      "280 79.0\n",
      "281 84.0\n",
      "282 45.0\n",
      "283 85.0\n",
      "284 54.0\n",
      "285 49.0\n",
      "286 67.0\n",
      "287 59.0\n",
      "288 137.0\n",
      "289 40.0\n",
      "290 67.0\n",
      "291 42.0\n",
      "292 61.0\n",
      "293 93.0\n",
      "294 50.0\n",
      "295 51.0\n",
      "296 60.0\n",
      "297 71.0\n",
      "298 102.0\n",
      "299 48.0\n",
      "300 50.0\n",
      "301 91.0\n",
      "302 115.0\n",
      "303 74.0\n",
      "304 76.0\n",
      "305 45.0\n",
      "306 57.0\n",
      "307 98.0\n",
      "308 48.0\n",
      "309 62.0\n",
      "310 55.0\n",
      "311 57.0\n",
      "312 123.0\n",
      "313 117.0\n",
      "314 98.0\n",
      "315 101.0\n",
      "316 47.0\n",
      "317 49.0\n",
      "318 51.0\n",
      "319 93.0\n",
      "320 58.0\n",
      "321 48.0\n",
      "322 49.0\n",
      "323 89.0\n",
      "324 55.0\n",
      "325 52.0\n",
      "326 78.0\n",
      "327 51.0\n",
      "328 45.0\n",
      "329 53.0\n",
      "330 49.0\n",
      "331 71.0\n",
      "332 102.0\n",
      "333 53.0\n",
      "334 47.0\n",
      "335 117.0\n",
      "336 101.0\n",
      "337 72.0\n",
      "338 121.0\n",
      "339 42.0\n",
      "340 89.0\n",
      "341 73.0\n",
      "342 63.0\n",
      "343 118.0\n",
      "344 91.0\n",
      "345 69.0\n",
      "346 86.0\n",
      "347 77.0\n",
      "348 175.0\n",
      "349 107.0\n",
      "350 41.0\n",
      "351 84.0\n",
      "352 68.0\n",
      "353 64.0\n",
      "354 59.0\n",
      "355 40.0\n",
      "356 44.0\n",
      "357 57.0\n",
      "358 97.0\n",
      "359 40.0\n",
      "360 49.0\n",
      "361 84.0\n",
      "362 75.0\n",
      "363 95.0\n",
      "364 56.0\n",
      "365 51.0\n",
      "366 74.0\n",
      "367 70.0\n",
      "368 56.0\n",
      "369 87.0\n",
      "370 55.0\n",
      "371 45.0\n",
      "372 52.0\n",
      "373 71.0\n",
      "374 55.0\n",
      "375 75.0\n",
      "376 69.0\n",
      "377 76.0\n",
      "378 53.0\n",
      "379 76.0\n",
      "380 44.0\n",
      "381 137.0\n",
      "382 49.0\n",
      "383 118.0\n",
      "384 99.0\n",
      "385 50.0\n",
      "386 55.0\n",
      "387 64.0\n",
      "388 54.0\n",
      "389 57.0\n",
      "390 48.0\n",
      "391 59.0\n",
      "392 66.0\n",
      "393 89.0\n",
      "394 45.0\n",
      "395 91.0\n",
      "396 99.0\n",
      "397 105.0\n",
      "398 78.0\n",
      "399 54.0\n",
      "400 57.0\n",
      "401 44.0\n",
      "402 60.0\n",
      "403 53.0\n",
      "404 41.0\n",
      "405 186.0\n",
      "406 99.0\n",
      "407 74.0\n",
      "408 90.0\n",
      "409 93.0\n",
      "410 80.0\n",
      "411 89.0\n",
      "412 46.0\n",
      "413 57.0\n",
      "414 69.0\n",
      "415 128.0\n",
      "416 85.0\n",
      "417 80.0\n",
      "418 198.0\n",
      "419 62.0\n",
      "420 68.0\n",
      "421 60.0\n",
      "422 129.0\n",
      "423 72.0\n",
      "424 97.0\n",
      "425 66.0\n",
      "426 53.0\n",
      "427 158.0\n",
      "428 78.0\n",
      "429 49.0\n",
      "430 107.0\n",
      "431 118.0\n",
      "432 68.0\n",
      "433 51.0\n",
      "434 177.0\n",
      "435 65.0\n",
      "436 78.0\n",
      "437 49.0\n",
      "438 76.0\n",
      "439 112.0\n",
      "440 141.0\n",
      "441 200.0\n"
     ]
    }
   ],
   "source": [
    "noise_scaling = .1\n",
    "params = np.random.rand(4, 1) * 2 - 1\n",
    "best_reward = 0\n",
    "for episode in range(1000):\n",
    "    new_params = params + (np.random.rand(4, 1) * 2 - 1) * noise_scaling\n",
    "    G, T = run_episode(env, new_params)\n",
    "    print(episode, G)\n",
    "    if G > best_reward:\n",
    "        best_reward = G\n",
    "        params = new_params\n",
    "        if G >= 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 51.0\n",
      "1 47.0\n",
      "2 75.0\n",
      "3 67.0\n",
      "4 66.0\n",
      "5 99.0\n",
      "6 85.0\n",
      "7 61.0\n",
      "8 91.0\n",
      "9 48.0\n",
      "10 112.0\n",
      "11 50.0\n",
      "12 49.0\n",
      "13 124.0\n",
      "14 73.0\n",
      "15 60.0\n",
      "16 87.0\n",
      "17 100.0\n",
      "18 112.0\n",
      "19 49.0\n"
     ]
    }
   ],
   "source": [
    "for episode in range(20):\n",
    "    G, T = run_episode(env, params)\n",
    "    print(episode, G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_gradient():\n",
    "    params = tf.get_variable('policy_params', [stateSize, nActions])\n",
    "    state = tf.placeholder('float', [None, stateSize])\n",
    "    linear = tf.matmul(state, params)\n",
    "    probs = tf.nn.softmax(linear)\n",
    "    actions = tf.placeholder('float', [None, nActions]) # one-hot encoding for actions\n",
    "    probs = tf.multiply(probs, actions)\n",
    "    probs = tf.reduce_sum(probs, reduction_indices=[1])\n",
    "    log_probs = tf.log(probs)\n",
    "    loss = -tf.reduce_sum(log_probs)\n",
    "    optimizer = tf.train.AdamOptimizer(.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_gradient():\n",
    "    state = tf.placeholder('float', [None, stateSize])\n",
    "    w1 = tf.get_variable('w1', [stateSize, 10])\n",
    "    b1 = tf.get_variable('b1', [10])\n",
    "    h1 = tf.nn.relu(tf.matmul(state, w1) + b1)\n",
    "    w2 = tf.get_variable('w2', [10, 1])\n",
    "    b2 = tf.get_variable('b2', [1])\n",
    "    pred = tf.matmul(h1, w2) + b2\n",
    "    vals = tf.placeholder('float', [None, 1])\n",
    "    deltas = pred - vals\n",
    "    loss = tf.nn.l2_loss(deltas)\n",
    "    optimizer = tf.train.AdadeltaOptimizer(.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-930d0e8d230a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "pp, ps = policy_gradient()\n",
    "state = env.reset()\n",
    "actions = []\n",
    "for t in range(200):\n",
    "    state = np.expand_dims(state, axis=0)\n",
    "    probs = sess.run(pp, feeddict={ps:state})\n",
    "    action = 0 if random.rand() < probs[0][0] else 1\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_gradient():  \n",
    "    params = tf.get_variable(\"policy_parameters\",[4,2])\n",
    "    state = tf.placeholder(\"float\",[None,4])\n",
    "    actions = tf.placeholder(\"float\",[None,2])\n",
    "    advantages = tf.placeholder(\"float\",[None,1])\n",
    "    linear = tf.matmul(state,params)\n",
    "    probabilities = tf.nn.softmax(linear)\n",
    "    good_probabilities = tf.reduce_sum(tf.multiply(probabilities, actions),reduction_indices=[1])\n",
    "    # maximize the log probability\n",
    "    log_probabilities = tf.log(good_probabilities)\n",
    "    # insert the elementwise multiplication by advantages\n",
    "    eligibility = log_probabilities * advantages\n",
    "    loss = -tf.reduce_sum(eligibility)\n",
    "    optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable policy_parameters already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-18-9498856638f2>\", line 2, in policy_gradient\n    params = tf.get_variable(\"policy_parameters\",[4,2])\n  File \"<ipython-input-19-930d0e8d230a>\", line 1, in <module>\n    pp, ps = policy_gradient()\n  File \"/home/wangxing/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5706c0a8e474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpl_probabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-9498856638f2>\u001b[0m in \u001b[0;36mpolicy_gradient\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpolicy_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"policy_parameters\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0madvantages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1482\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1232\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    536\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    490\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    857\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 859\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    860\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable policy_parameters already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-18-9498856638f2>\", line 2, in policy_gradient\n    params = tf.get_variable(\"policy_parameters\",[4,2])\n  File \"<ipython-input-19-930d0e8d230a>\", line 1, in <module>\n    pp, ps = policy_gradient()\n  File \"/home/wangxing/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "pl_probabilities, pl_state = policy_gradient()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
